{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21970d2",
   "metadata": {},
   "source": [
    "# Transform Data: Time and Frequency Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d8f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy import signal\n",
    "from scipy.stats import kurtosis\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2b5bf",
   "metadata": {},
   "source": [
    "### Convert to Frequency domain via Fast Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1868b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast Fourier Transform\n",
    "    # Transform signal data to frequency domain\n",
    "    # Source: https://github.com/DovileDo/BearingDegradationStageDetection/blob/main/src/data/TransformToFrequencyDomain.py\n",
    "    # Source: https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.rfftfreq.html\n",
    "        # FFT returns Array of length n//2 + 1 containing the sample frequencies.\n",
    "\n",
    "def FFT(arr, rate, q):\n",
    "    X = np.empty((0, int((rate/q/2)+1)), float)\n",
    "\n",
    "    for i in range(0, len(arr), int(rate/q)): # based on 1-second snapshots at given rate (20,480 Hz sampling frequency)\n",
    "        # down-sampling by a factor of q\n",
    "        x = np.abs(rfft(arr[i : i + int(rate/q)])) #sample\n",
    "        X = np.append(X, np.array([x]), axis=0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004a2ea",
   "metadata": {},
   "source": [
    "### Calculate Time Series attributes\n",
    "\n",
    " - Source: https://github.com/DovileDo/BearingDegradationStageDetection/blob/main/src/data/TransformToFrequencyDomain.py\n",
    " - Source: https://github.com/DovileDo/BearingDegradationStageDetection/blob/main/src/data/Manual_labeling.py\n",
    "     - Sahoo & Mohanty (\"Multiclass Bearing Fault Classification Using Features Learned by a Deep Neural Network\") identify the highest magnitude frequency of each observation, and the smoothed maximum acceleration (calculated by averaging the five highest absolute acceleration measurements in the time domain) as predictive of bearing failure. These two attributes can be useful for manual labeling of bearing degradation stage.\n",
    " - Source: https://www.kaggle.com/code/furkancitil/nasa-bearing-dataset-rul-prediction\n",
    "\n",
    "\n",
    "Time-series features are extracted from the data: \n",
    "\n",
    "\n",
    "**Definition and formula of the features:**\n",
    "* ***Absolute Mean*** $$\\overline{x} = \\frac{1}{N}\\sum_{i=1}^{N}|x_i| $$\n",
    "\n",
    "* ***Standard Deviation:*** $$\\sigma         = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(x_i - \\overline{x})^2}$$\n",
    "* ***Skewness:*** \n",
    "Asymmetry of a signal distribution. Faults can impact distribution symmetry and therefore increase the level of skewness.\n",
    "$$\\mathrm{Sk} = \\frac{1}{N}\\sum_{i=1}^{N}\\frac{(x_i-\\overline{x})^3}{\\sigma^3}$$\n",
    "* ***Kurtosis:***\n",
    "Length of the tails of a signal distribution, or equivalently, how outlier prone the signal is. Developing faults can increase the number of outliers, and therefore increase the value of the kurtosis metric.\n",
    "$$\\mathrm{K} = \\frac{1}{N}\\sum_{i=1}^{N}\\frac{(x_i-\\overline{x})^4}{\\sigma^4}$$\n",
    "* ***Entropy:***$$ H(X) = -\\sum_{i=1}^{N} P(x_i)\\log{P(x_i)} $$\n",
    "                            \n",
    "* ***RMS:*** $$x_{rms} =\\sqrt{(\\frac{1}{N})\\sum_{i=1}^{N}(x)^{2}}$$\n",
    "\n",
    "* ***Peak to Peak:*** $$ x_p = \\max \\mathrm{value} - \\min \\mathrm{value}$$\n",
    "\n",
    "* ***Crest Factor:*** \n",
    "Peak value divided by the RMS. Faults often first manifest themselves in changes in the peakiness of a signal before they manifest in the energy represented by the signal root mean squared. The crest factor can provide an early warning for faults when they first develop. \n",
    "$$x_{crest} =\\frac{\\max \\mathrm{value}}{\\mathrm{x_{rms}}}$$\n",
    "\n",
    "* ***Clearence Factor:*** \n",
    "Peak value divided by the squared mean value of the square roots of the absolute amplitudes. For rotating machinery, this feature is maximum for healthy bearings and goes on decreasing for defective ball, defective outer race, and defective inner race respectively. The clearance factor has the highest separation ability for defective inner race faults.\n",
    "$$ x_{clear} = \\frac{x_p}{(\\frac{1}{N}\\sum_{i=1}^{N}\\sqrt{|x_i|})^2}  $$\n",
    "\n",
    "* ***Shape Factor:*** \n",
    "RMS divided by the mean of the absolute value. Shape factor is dependent on the signal shape while being independent of the signal dimensions.\n",
    "$$\\frac{x_{rms}}{\\overline{x}}$$\n",
    "\n",
    "* ***Impulse:*** \n",
    "Compare the height of a peak to the mean level of the signal.\n",
    "$$\\frac{\\max \\mathrm{value}}{\\overline{x}}  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c9a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to Time Domain\n",
    "    # Source: https://github.com/DovileDo/BearingDegradationStageDetection/blob/main/src/data/TransformToFrequencyDomain.py\n",
    "    # Source: https://github.com/DovileDo/BearingDegradationStageDetection/blob/main/src/data/Manual_labeling.py\n",
    "        # Sahoo & Mohanty (\"Multiclass Bearing Fault Classification Using Features Learned by a Deep Neural Network\") \n",
    "        # identify the highest magnitude frequency of each observation, and the smoothed maximum acceleration \n",
    "            # (calculated by averaging the five highest absolute acceleration measurements in the time domain)\n",
    "        # as predictive of bearing failure. These two attributes can be useful for manual labeling of bearing degradation stage.\n",
    "    # Source: https://www.kaggle.com/code/furkancitil/nasa-bearing-dataset-rul-prediction\n",
    "\n",
    "def time_features(arr, rate, q):\n",
    "\n",
    "    zerocross = []\n",
    "    ktosis = []\n",
    "    rms = []\n",
    "    peaks = []\n",
    "    mean = []\n",
    "    mean_abs = []\n",
    "    std = []\n",
    "    median = []\n",
    "    skewness = []\n",
    "    entrpy = []\n",
    "    energy = []\n",
    "    shapiro = []\n",
    "    kl = []\n",
    "    rkl = []\n",
    "    crest = []\n",
    "    abs_acc_5 = []\n",
    "    max_freq = []\n",
    "    max_abs = []\n",
    "    shape = []\n",
    "    impulse = []\n",
    "    p2p = []\n",
    "    \n",
    "    for i in range(0, len(arr), int(rate/q)): # based on 1-second snapshots at given rate (20,480 Hz sampling frequency)\n",
    "        # down-sampling by a factor of 10\n",
    "        sample = arr[i : i + int(rate/q)]\n",
    "        \n",
    "        # smoothed maximum acceleration calculated by avg. 5 highest absolute acceleration measurements in the time domain.\n",
    "        Hpositive = abs(sample)\n",
    "        Hmax = np.argpartition(Hpositive, -5)[-5:]\n",
    "        Hmean = np.mean(Hpositive[Hmax])\n",
    "        abs_acc_5.append(Hmean)\n",
    "        \n",
    "        # highest magnitude frequency of each observation\n",
    "        Hf = np.abs(rfft(sample))\n",
    "        Hind = np.argpartition(Hf, -1)[-1:]# * 10\n",
    "        max_freq.append(int(Hf[Hind]))\n",
    "        \n",
    "        # absolute max value\n",
    "        abs_max = np.abs(sample).max()\n",
    "        max_abs.append(abs_max)\n",
    "        \n",
    "        # zero crossing\n",
    "        c = ((sample[:-1] * sample[1:]) < 0).sum() + (sample == 0).sum()\n",
    "        zerocross.append(c)\n",
    "        \n",
    "        # kurtosis: distribution tail\n",
    "        kur = kurtosis(sample)\n",
    "        ktosis.append(kur)\n",
    "        \n",
    "        # Root Mean Square (RMS)\n",
    "        rms_ = np.sqrt(np.mean(sample**2))\n",
    "        rms.append(rms_)\n",
    "        \n",
    "        # Number of peaks\n",
    "        pks, _ = find_peaks(sample)\n",
    "        peaks.append(len(pks) / len(sample))\n",
    "        \n",
    "        # Mean\n",
    "        mean.append(np.mean(sample))\n",
    "        \n",
    "        # Abs. Mean\n",
    "        abs_mean_ = np.abs(sample).mean()\n",
    "        mean_abs.append(abs_mean_) \n",
    "        \n",
    "        # shape = rms / mean_abs\n",
    "        shape.append(rms_ / abs_mean_)\n",
    "        \n",
    "        # impulse = max_abs / mean_abs\n",
    "        impulse.append(abs_max / abs_mean_)\n",
    "        \n",
    "        # peak-to-peak = max_val - min_val\n",
    "        p2p.append(np.max(sample) - np.min(sample))\n",
    "        \n",
    "        # Median\n",
    "        abs_med_ = np.median(abs(sample))\n",
    "        median.append(abs_med_)\n",
    "        \n",
    "        # std\n",
    "        std.append(np.std(sample))\n",
    "        \n",
    "        # Skewness\n",
    "        skewness.append(stats.skew(sample))\n",
    "        \n",
    "        # Entropy - extract shannon entropy (cut signals to 500 bins)\n",
    "        entrpy.append(entropy(pd.cut(sample, 500).value_counts()))\n",
    "        \n",
    "        # Crest\n",
    "        crest.append(\n",
    "            np.max(np.abs(sample)) / np.sqrt(np.mean(np.square(sample))))\n",
    "        \n",
    "        # Energy\n",
    "        energy.append(np.sum(np.abs(sample) ** 2))\n",
    "        \n",
    "        # Shapiro\n",
    "        s, p = stats.shapiro(sample)\n",
    "        shapiro.append(s)\n",
    "        \n",
    "        # KL\n",
    "        x = np.linspace(min(sample), max(sample), 100)\n",
    "        en = stats.entropy(\n",
    "            stats.gaussian_kde(sample).evaluate(x),\n",
    "            stats.norm.pdf(x, np.mean(sample), np.std(sample)),\n",
    "        )\n",
    "        kl.append(en)\n",
    "        \n",
    "        # Reverse KL\n",
    "        x = np.linspace(min(sample), max(sample), 100)\n",
    "        ren = stats.entropy(\n",
    "            stats.norm.pdf(x, np.mean(sample), np.std(sample)),\n",
    "            stats.gaussian_kde(sample).evaluate(x),\n",
    "        )\n",
    "        rkl.append(ren)\n",
    "        \n",
    "    df = pd.DataFrame(zerocross, columns=[\"zerocross\"])\n",
    "    df[\"ktosis\"] = ktosis\n",
    "    df[\"rms\"] = rms\n",
    "    df[\"peaks\"] = peaks\n",
    "    df[\"mean\"] = mean\n",
    "    df[\"mean_abs\"] = mean_abs\n",
    "    df[\"std\"] = std\n",
    "    df[\"median\"] = median\n",
    "    df[\"skewness\"] = skewness\n",
    "    df[\"crest\"] = crest\n",
    "    df[\"entrpy\"] = entrpy\n",
    "    df[\"energy\"] = energy\n",
    "    df[\"shapiro\"] = shapiro\n",
    "    df[\"kl\"] = kl\n",
    "    df[\"rkl\"] = rkl\n",
    "    df[\"abs_acc_5\"] = abs_acc_5\n",
    "    df[\"max_freq\"] = max_freq\n",
    "    df[\"max_abs\"] = max_abs\n",
    "    df[\"shape\"] = shape\n",
    "    df[\"impulse\"] = impulse\n",
    "    df[\"p2p\"] = p2p\n",
    "    \n",
    "    mask = df[\"kl\"] != np.inf\n",
    "    df.loc[~mask, \"kl\"] = df.loc[mask, \"kl\"].max()\n",
    "\n",
    "    mask = df[\"rkl\"] != np.inf\n",
    "    df.loc[~mask, \"rkl\"] = df.loc[mask, \"rkl\"].max()\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
